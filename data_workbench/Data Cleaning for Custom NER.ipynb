{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fa46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cleantext import clean\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data-team-duckies-2022-07-21.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb595e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()[[\"content\", \"gen_title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449be937",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 300\n",
    "pd.options.display.max_rows = 1800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d094af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_product = df[['gen_title', 'content']][df['gen_title'].str.startswith(\"New!\")]\n",
    "df_new_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in df_new_product.iterrows():\n",
    "    \n",
    "    # get original title and remove newline character\n",
    "    original_title = data[\"gen_title\"].replace(\"\\n\", \" \")\n",
    "    print(original_title)\n",
    "    \n",
    "    # use regex to remove unit numbers, money values, x-for-y, x% off etc.\n",
    "    regex_sweeped_up = []\n",
    "    moneyValues = parseMoneyValues(original_title)\n",
    "    unitNumbers = parseUnitNumber(original_title)\n",
    "    xForY = parseXForY(original_title)\n",
    "    xPercentOff = parseXPercentOff(original_title)\n",
    "    \n",
    "    print(moneyValues)\n",
    "    print(unitNumbers)\n",
    "    print(xForY)\n",
    "    print(xPercentOff)\n",
    "    \n",
    "    \n",
    "#     title_tokenized = data[\"gen_title\"].split(\" \")\n",
    "#     product_name = \" \".join(title_tokenized[1:]).lower()\n",
    "#     content = data[\"content\"].lower()\n",
    "#     print(product_name)\n",
    "#     start = content.find(product_name)\n",
    "#     if start != -1:\n",
    "#         print(index, \",\", product_name, \",\", start)\n",
    "#     else:\n",
    "#         print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68421b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for unit number\n",
    "\n",
    "def parseUnitNumber(user_input):\n",
    "    pattern = \"(\\(?#?[A-Z0-9]{1,3}-[A-Z0-9]{1,3}-?(?:[0-9A-Z]{1,})?(?:/[A-Z0-9]{1,})*\\)?)\"\n",
    "    return re.findall(pattern, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"(\\(?#?[A-Z0-9]{1,3}-[A-Z0-9]{1,3}-?(?:[0-9A-Z]{1,})?(?:/[A-Z0-9]{1,})*\\)?)\"\n",
    "user_input = input()\n",
    "re.findall(pattern, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for date parsing\n",
    "\n",
    "# ^(\\d{4})(-|\\/)(\\d{2})(-|\\/)(\\d{2})T(\\d{2}):(\\d{2}):(\\d{2})\\.(\\d{3})\n",
    "# ^([0-2][0-9]|(3)[0-1])(\\.|-|\\/)(((0)[0-9])|((1)[0-2]))(\\.|-|\\/)\\d{4}$ - simple data DD/MM/YYYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012413ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for X% off\n",
    "\n",
    "def parseXPercentOff(user_input):\n",
    "    pattern = \"((?:\\d{1,2})%(?:[-\\s][Oo][Ff][Ff]*?)?|(?:[Ss]ave [Uu]p to|[Ss]ave|[Ee]njoy)\\s?(?:of\\s)?(?:\\d{1,2})%)\"\n",
    "    if re.findall(pattern, user_input):\n",
    "         return re.findall(pattern, user_input)\n",
    "    else:\n",
    "        return \"not found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6afd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"((?:\\d{1,2})%(?:[-\\s][Oo][Ff][Ff]\\*?)?|(?:[Ss]ave [Uu]p to|[Ss]ave|[Ee]njoy)\\s?(?:of\\s)?(?:\\d{1,2})%)\"\n",
    "user_input = input()\n",
    "re.findall(pattern, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020949a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for X-for-Y\n",
    "\n",
    "def parseXForY(user_input):\n",
    "    pattern = \"(?:[Bb][Uu][Yy] |[Gg][Ee][Tt] )?[0-9][-|\\s](?:[Ff]or)[-|\\s][0-9]\"\n",
    "    if re.findall(pattern, user_input):\n",
    "        return re.findall(pattern, user_input)\n",
    "    else:\n",
    "        return \"not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980abc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"(?:[Bb][Uu][Yy] |[Gg][Ee][Tt] )?[0-9][-|\\s](?:[Ff]or)[-|\\s][0-9]\"\n",
    "user_input = input()\n",
    "re.findall(pattern, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fe650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex for money values\n",
    "\n",
    "def parseMoneyValues(user_input):\n",
    "    pattern = \"((?:[Ss]ave [Uu]p to |[Ss]ave |[Uu]nder )?\\$[\\d,]+(?:\\.\\d*)?(?:\\*)?(?:[Ff][Oo]{Rr})?)\"\n",
    "    if re.findall(pattern, user_input):\n",
    "        return re.findall(pattern, user_input)\n",
    "    else:\n",
    "        return \"not found\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd4cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"((?:[Ss]ave [Uu]p to |[Ss]ave |[Uu]nder )?\\$[\\d,]+(?:\\.\\d*)?(?:\\*)?[-|\\s]?(?:[Ff][Oo][Rr])?)\"\n",
    "user_input = input()\n",
    "re.findall(pattern, user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d15538",
   "metadata": {},
   "source": [
    "<h2> New Outlets <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_outlet = df[['gen_title', 'content']][df['gen_title'].str.startswith(\"New Outlet!\")]\n",
    "pd.options.display.max_rows = 300\n",
    "df_new_outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b6e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_outlet.at[7351,'gen_title']= 'New Outlet! Novena Square 2 #02-10/18/25/27'\n",
    "df_new_outlet.at[7051,'gen_title']= 'New Outlet! Gain City Megastore @ Sungei Kadut'\n",
    "df_new_outlet.at[40,'gen_title']= 'New Outlet! Fairprice Hub #01-56-57/57A & 20% OFF* with Min. Spend'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a07957",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_out = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7fd1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, data in df_new_outlet.iterrows():\n",
    "    print(index)\n",
    "    outletTries = []\n",
    "    \n",
    "    # get original title and remove newline character\n",
    "    original_title = data[\"gen_title\"].replace(\"\\n\", \" \")\n",
    "    print(original_title)\n",
    "\n",
    "    \n",
    "\n",
    "    # remove \"New Outline!\"\n",
    "    outlet_tokenized = title_tokenized[2:]\n",
    "#     print(outlet_tokenized)\n",
    "\n",
    "    # remove and collect unit numbers\n",
    "    unit_numbers = parseUnitNumber(original_title)\n",
    "    outlet_tokenized_drop_un = [token for token in outlet_tokenized if not parseUnitNumber(token)]\n",
    "#     print(unit_numbers)\n",
    "    print(outlet_tokenized_drop_un)\n",
    "    if outlet_tokenized_drop_un:\n",
    "        outletNameTry1 = \" \".join(outlet_tokenized_drop_un)\n",
    "        outletTries.append(outletNameTry1)\n",
    "    \n",
    "\n",
    "\n",
    "    # splitting title into beforeAt and afterAt (eg. Now Open @ Funan (#02-36))\n",
    "    atFlag = False\n",
    "    outlet_tokenized_copy = outlet_tokenized_drop_un.copy()\n",
    "    for index, token in enumerate(outlet_tokenized_drop_un):\n",
    "        if token == \"@\" or token == \"at\" or token == \"At\" or token == \"in\":\n",
    "            beforeAt = outlet_tokenized_copy[:index]\n",
    "            afterAt = outlet_tokenized_copy[index + 1:]\n",
    "            atFlag = True\n",
    "            print(beforeAt)\n",
    "            if beforeAt:\n",
    "                outletNameTry2 = \" \".join(beforeAt)\n",
    "                outletTries.append(outletNameTry2)\n",
    "            print(afterAt)\n",
    "            if afterAt:\n",
    "                outletNameTry3 = \" \".join(afterAt)\n",
    "                outletTries.append(outletNameTry3)\n",
    "\n",
    "    # splitting into before '+' and after '+' (eg. Causeway Point #03-26 + FREE* $50 Cash Voucher)\n",
    "\n",
    "    if atFlag:\n",
    "        for index, token in enumerate(beforeAt):\n",
    "            if token == \"+\" or token == \"&\" or token in \"FromFROMfrom\":\n",
    "                beforeAtbeforePlus = beforeAt[:index]\n",
    "                beforeAtafterPlus = beforeAt[index + 1:]\n",
    "#                 print(beforeAtbeforePlus)\n",
    "#                 print(beforeAtafterPlus)\n",
    "\n",
    "        for index, token in enumerate(afterAt):\n",
    "            if token == \"+\" or token == \"&\" or token in \"FromFROMfrom\":\n",
    "                AfterAtbeforePlus = afterAt[:index]\n",
    "                AfterAtafterPlus = afterAt[index + 1:]\n",
    "                print(AfterAtbeforePlus)\n",
    "                if AfterAtbeforePlus:\n",
    "                    outletNameTry4 = \" \".join(AfterAtbeforePlus)\n",
    "                    outletTries.append(outletNameTry4)\n",
    "#                 print(AfterAtafterPlus)\n",
    "    else:\n",
    "        for index, token in enumerate(outlet_tokenized_drop_un):\n",
    "            if token == \"+\" or token == \"&\" or token in \"FromFROMfrom\":\n",
    "                originalBeforePlus = outlet_tokenized_drop_un[:index]\n",
    "                originalAfterPlus = outlet_tokenized_drop_un[index + 1:]\n",
    "                print(originalBeforePlus)\n",
    "                if originalBeforePlus:\n",
    "                    outletNameTry5 = \" \".join(originalBeforePlus)\n",
    "                    outletTries.append(outletNameTry5)\n",
    "#                 print(originalAfterPlus)\n",
    "    \n",
    "    output_content_bytes = bytes(clean(data[\"content\"], no_emoji=True, no_emails=True, no_urls=True, no_numbers=True, lower=False), \"utf-8\")\n",
    "    output_content_string = output_content_bytes.decode(\"utf-8\").replace(\"\\n\", \" \")\n",
    "    \n",
    "    row_out = {'title': original_title, 'content': output_content_string, 'outletNameTries': outletTries}\n",
    "    outlet_out.append(row_out)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outlet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec99cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outlet_out[3]['content'])\n",
    "start = outlet_out[3]['content'].find('GR.ID')\n",
    "end = start + len('GR.ID')\n",
    "\n",
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4693666",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlet_out[4]['outletNameTries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f6efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_out = []\n",
    "\n",
    "for row in outlet_out:\n",
    "    textSegmentAnnotations = []\n",
    "    for trial in row['outletNameTries']:\n",
    "        if row['content'].find(trial) != -1:\n",
    "            start = row['content'].find(trial)\n",
    "            end = start + len(trial)\n",
    "            textSegmentDict = {\"startOffset\": start, \n",
    "                               \"endOffset\": end,\n",
    "                               \"displayName\": \"Outlet Location\"}\n",
    "            textSegmentAnnotations.append(textSegmentDict)\n",
    "    if textSegmentAnnotations:\n",
    "        rowDict = {\"textSegmentAnnotations\": textSegmentAnnotations, \"textContent\": row[\"content\"]}\n",
    "        vertex_out.append(rowDict)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
